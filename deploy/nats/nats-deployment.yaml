# NATS JetStream Deployment for OpenClaw Memory
# Production deployments should use the NATS Helm chart or NATS Operator
---
apiVersion: v1
kind: Namespace
metadata:
  name: openclaw
  labels:
    app.kubernetes.io/name: openclaw
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nats-config
  namespace: openclaw
data:
  nats.conf: |
    # NATS Server Configuration for OpenClaw
    
    # Server identification
    server_name: openclaw-nats
    
    # Client connections
    port: 4222
    
    # HTTP monitoring
    http_port: 8222
    
    # JetStream configuration
    jetstream {
      store_dir: /data/jetstream
      max_memory_store: 1Gi
      max_file_store: 10Gi
    }
    
    # Cluster configuration (for HA deployment)
    # cluster {
    #   name: openclaw-cluster
    #   port: 6222
    #   routes: [
    #     nats-route://nats-0.nats.openclaw.svc:6222
    #     nats-route://nats-1.nats.openclaw.svc:6222
    #     nats-route://nats-2.nats.openclaw.svc:6222
    #   ]
    # }
    
    # Logging
    debug: false
    trace: false
    logtime: true
    
    # Limits
    max_connections: 1000
    max_payload: 8MB
    max_pending: 64MB
    
    # Authorization (basic - use NKEY/JWT for production)
    # authorization {
    #   users: [
    #     { user: openclaw, password: $NATS_PASSWORD }
    #   ]
    # }
---
apiVersion: v1
kind: Service
metadata:
  name: nats
  namespace: openclaw
  labels:
    app.kubernetes.io/name: nats
    app.kubernetes.io/component: messaging
spec:
  selector:
    app.kubernetes.io/name: nats
  ports:
    - name: client
      port: 4222
      targetPort: 4222
    - name: cluster
      port: 6222
      targetPort: 6222
    - name: monitor
      port: 8222
      targetPort: 8222
  clusterIP: None  # Headless for StatefulSet
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nats
  namespace: openclaw
  labels:
    app.kubernetes.io/name: nats
    app.kubernetes.io/component: messaging
spec:
  serviceName: nats
  replicas: 1  # Increase to 3 for HA
  selector:
    matchLabels:
      app.kubernetes.io/name: nats
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nats
    spec:
      terminationGracePeriodSeconds: 30
      containers:
        - name: nats
          image: nats:2.10-alpine
          ports:
            - containerPort: 4222
              name: client
            - containerPort: 6222
              name: cluster
            - containerPort: 8222
              name: monitor
          command:
            - nats-server
            - --config
            - /etc/nats/nats.conf
          volumeMounts:
            - name: config
              mountPath: /etc/nats
            - name: data
              mountPath: /data
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 1000m
              memory: 2Gi
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8222
            initialDelaySeconds: 10
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8222
            initialDelaySeconds: 5
            periodSeconds: 10
      volumes:
        - name: config
          configMap:
            name: nats-config
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi
---
# NATS Box for debugging (optional)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nats-box
  namespace: openclaw
  labels:
    app.kubernetes.io/name: nats-box
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nats-box
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nats-box
    spec:
      containers:
        - name: nats-box
          image: natsio/nats-box:0.14.1
          command: ["tail", "-f", "/dev/null"]
          env:
            - name: NATS_URL
              value: nats://nats.openclaw.svc:4222
